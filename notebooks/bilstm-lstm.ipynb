{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on:\n",
        "https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF5NMHVx2BTS"
      },
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4HtQ4IPGJtX",
        "outputId": "00f15e83-9dde-486d-9f8a-1e2e17aa45c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: plot_keras_history in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (1.1.38)\n",
            "Requirement already satisfied: matplotlib in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from plot_keras_history) (3.6.2)\n",
            "Requirement already satisfied: pandas in /home/digitalhub/.local/lib/python3.8/site-packages (from plot_keras_history) (1.3.4)\n",
            "Requirement already satisfied: scipy in /home/digitalhub/.local/lib/python3.8/site-packages (from plot_keras_history) (1.7.2)\n",
            "Requirement already satisfied: support_developer>=1.0.2 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from plot_keras_history) (1.0.5)\n",
            "Requirement already satisfied: sanitize_ml_labels>=1.0.48 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from plot_keras_history) (1.0.50)\n",
            "Requirement already satisfied: compress_json in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from sanitize_ml_labels>=1.0.48->plot_keras_history) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.19 in /home/digitalhub/.local/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (1.21.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (9.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (1.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/digitalhub/.local/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->plot_keras_history) (1.16.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from pandas->plot_keras_history) (2022.6)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: keras in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (2.7.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: tensorflow in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (2.7.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (3.6.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (4.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.21.4)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (56.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/digitalhub/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/digitalhub/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/digitalhub/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/digitalhub/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.2.2)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: pyconll in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (3.1.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-47df4zys\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-47df4zys\n",
            "Requirement already satisfied: keras in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from keras-contrib==2.0.8) (2.7.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: conllu in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (4.5.2)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install plot_keras_history\n",
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install pyconll\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install conllu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuRfitpw2NAW"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M3XPDgA9FP0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-02 15:12:21.741672: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-12-02 15:12:21.741688: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import operator\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pyconll\n",
        "import tensorflow as tf\n",
        "\n",
        "from plot_keras_history import plot_history\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from keras_contrib.utils import save_load_utils\n",
        "\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib import losses\n",
        "from keras_contrib import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d-3Qy8N2Sk_"
      },
      "source": [
        "# Baseline model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orqxebPu3cBh"
      },
      "source": [
        "## Import and preprocess general data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wYk1xx-yolmf",
        "outputId": "9ee5b10b-007d-4fd2-e386-d8699c50cba4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>NaN</td>\n",
              "      <td>they</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>NaN</td>\n",
              "      <td>responded</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>NaN</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>NaN</td>\n",
              "      <td>attack</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1048575 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Sentence #           Word Tag\n",
              "0        Sentence: 1      Thousands   O\n",
              "1                NaN             of   O\n",
              "2                NaN  demonstrators   O\n",
              "3                NaN           have   O\n",
              "4                NaN        marched   O\n",
              "...              ...            ...  ..\n",
              "1048570          NaN           they   O\n",
              "1048571          NaN      responded   O\n",
              "1048572          NaN             to   O\n",
              "1048573          NaN            the   O\n",
              "1048574          NaN         attack   O\n",
              "\n",
              "[1048575 rows x 3 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Download Groningen Meaning Bank (GMB) data: https://gmb.let.rug.nl/about.php for baseline\n",
        "train_path = 'ner_data/ner_dataset.csv'\n",
        "bl_data = pd.read_csv(train_path, encoding=\"iso-8859-1\", header=0)\n",
        "bl_data.drop(columns=['POS'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of sentences in the dataset: 47,959\n",
            "Total words in the dataset: 1,048,575\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of sentences in the dataset: {:,}\".format(bl_data[\"Sentence #\"].nunique()))\n",
        "print(\"Total words in the dataset: {:,}\".format(bl_data.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3YKTUnjj0l26"
      },
      "outputs": [],
      "source": [
        "bl_data.ffill(inplace=True) #forward fill sentence column\n",
        "bl_data['Sentence #'] = bl_data['Sentence #'].apply(lambda i: i[9:]) #reformat sentence column\n",
        "bl_data[\"Sentence #\"] = bl_data[\"Sentence #\"].astype(\"int32\") #change sentence column type\n",
        "bl_data.rename(columns = {'Sentence #':'Sentence'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xZUPau29yeyM"
      },
      "outputs": [],
      "source": [
        "#Function to get dictionary of all unique items ('Word' and 'Tag')\n",
        "#Returns 1 dictionary of index:item pairs and 1 dictionary of item:index pairs\n",
        "def get_dict_map(data, column):\n",
        "    item2idx = {}\n",
        "    idx2item = {}\n",
        "    \n",
        "    corpus = list(set(data[column].to_list())) #get list of unique words/tags\n",
        "\n",
        "    idx2item = {index:item for index, item in enumerate(corpus)}\n",
        "    item2idx = {item:index for index, item in enumerate(corpus)}\n",
        "    \n",
        "    return idx2item, item2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MT5euMKdrlXU"
      },
      "outputs": [],
      "source": [
        "def group_data(data, word2idx, tag2idx):\n",
        "\n",
        "  #Create index columns for 'Word' and 'Tag'\n",
        "  data['Word_index'] = data['Word'].map(word2idx)\n",
        "  data['Tag_index'] = data['Tag'].map(tag2idx)\n",
        "\n",
        "  #For each sentence, create a sequence of words, pos, tags, word indexes, tag indexes\n",
        "  data_group = data.groupby(['Sentence'],as_index=False)['Word', 'Tag', 'Word_index', 'Tag_index'].agg(lambda x: list(x))\n",
        "  return data_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RbNB4egRs69m"
      },
      "outputs": [],
      "source": [
        "  #Get index to word, word to index, index to tag, tag to index mapping\n",
        "  idx2word, word2idx = get_dict_map(bl_data, 'Word')\n",
        "  idx2tag, tag2idx = get_dict_map(bl_data, 'Tag')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOy7ygiXsRFB",
        "outputId": "a792c8e4-d1dc-4354-9635-e1e4576eed3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_41365/3682637150.py:8: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  data_group = data.groupby(['Sentence'],as_index=False)['Word', 'Tag', 'Word_index', 'Tag_index'].agg(lambda x: list(x))\n"
          ]
        }
      ],
      "source": [
        "bl_data_group = group_data(bl_data, word2idx, tag2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9iO01qSCIRU"
      },
      "source": [
        "## Prepare train and test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DknwTt8DBphQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences \n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5U1Up69KCPzd"
      },
      "outputs": [],
      "source": [
        "def get_pad_train_test_val(data_group, data):\n",
        "\n",
        "    #total num of unique words and tags\n",
        "    n_token = len(list(set(data['Word'].to_list())))\n",
        "    n_tag = len(list(set(data['Tag'].to_list())))\n",
        "\n",
        "    #Pad Words (X var)    \n",
        "    words = data_group['Word_index'].tolist()\n",
        "    maxlen = max([len(word) for word in words])\n",
        "    pad_tokens = pad_sequences(words, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
        "\n",
        "    #Pad Tags (y var) and convert it into one hot encoding\n",
        "    tags = data_group['Tag_index'].tolist()\n",
        "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
        "    n_tags = len(tag2idx)\n",
        "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags] #one hot encoding\n",
        "    \n",
        "    #Split train, test and validation set\n",
        "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
        "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n",
        "\n",
        "    print(\n",
        "        'train_words length:', len(train_tokens),\n",
        "        '\\ntrain_tags length:', len(train_tags),\n",
        "        '\\nval_words:', len(val_tokens),\n",
        "        '\\nval_tags:', len(val_tags),\n",
        "        '\\ntest_words length:', len(test_tokens),\n",
        "        '\\ntest_tags:', len(test_tags),\n",
        "\n",
        "    )\n",
        "    \n",
        "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G9ufmxhsP1d",
        "outputId": "b058521a-e613-412d-b96c-bb94c5c7bb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_words length: 32372 \n",
            "train_tags length: 32372 \n",
            "val_words: 10791 \n",
            "val_tags: 10791 \n",
            "test_words length: 4796 \n",
            "test_tags: 4796\n"
          ]
        }
      ],
      "source": [
        "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(bl_data_group, bl_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImDhTIKdJuIZ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Kh6O5Y5rJtyL"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential, Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "26Fhaoi_Etwv"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28ojiBSYK85f",
        "outputId": "ba178440-aa24-4efb-cd9c-9517b3287deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_dim:  35179 \n",
            "output_dim:  64 \n",
            "input_length:  104 \n",
            "n_tags:  17\n"
          ]
        }
      ],
      "source": [
        "input_dim = len(list(set(bl_data['Word'].to_list())))+1\n",
        "output_dim = 64\n",
        "input_length = max([len(s) for s in bl_data_group['Word_index'].tolist()])\n",
        "n_tags = len(tag2idx)\n",
        "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-0z_PN5zMEgf"
      },
      "outputs": [],
      "source": [
        "#Function to initialise and structure NN architecture\n",
        "def get_bilstm_lstm_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add Embedding layer\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "\n",
        "    # Add bidirectional LSTM\n",
        "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
        "\n",
        "    # Add LSTM\n",
        "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
        "\n",
        "    # Add timeDistributed Layer\n",
        "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n",
        "\n",
        "    #Optimiser \n",
        "    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qpLDPUIXNTj8"
      },
      "outputs": [],
      "source": [
        "#Function to train model, returns list of losses for each epoch\n",
        "def train_model(X, y, model):\n",
        "    loss = list()\n",
        "    for i in range(25): #run 25 epochs in total\n",
        "        # fit model for one epoch on this sequence\n",
        "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
        "        loss.append(hist.history['loss'][0])\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "y3FYLORKN878",
        "outputId": "81469123-6494-4beb-a637-2ce9542ceb3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-02 15:12:26.084864: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-12-02 15:12:26.084895: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dh-minion2): /proc/driver/nvidia/version does not exist\n",
            "2022-12-02 15:12:26.085589: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 104, 64)           2251456   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 104, 128)         66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 104, 64)           49408     \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 104, 17)          1105      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,368,017\n",
            "Trainable params: 2,368,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
            "26/26 [==============================] - 23s 748ms/step - loss: 1.0331 - accuracy: 0.9276 - val_loss: 0.3270 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 19s 718ms/step - loss: 0.2938 - accuracy: 0.9678 - val_loss: 0.2876 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 18s 701ms/step - loss: 0.2612 - accuracy: 0.9678 - val_loss: 0.3716 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 19s 727ms/step - loss: 0.2756 - accuracy: 0.9678 - val_loss: 0.2204 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 19s 750ms/step - loss: 0.2148 - accuracy: 0.9678 - val_loss: 0.1954 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 21s 795ms/step - loss: 0.2023 - accuracy: 0.9678 - val_loss: 0.1840 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 774ms/step - loss: 0.1760 - accuracy: 0.9678 - val_loss: 0.1707 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 769ms/step - loss: 0.1844 - accuracy: 0.9678 - val_loss: 0.1792 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 783ms/step - loss: 0.1700 - accuracy: 0.9678 - val_loss: 0.1636 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 19s 746ms/step - loss: 0.1598 - accuracy: 0.9678 - val_loss: 0.1623 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 19s 747ms/step - loss: 0.1519 - accuracy: 0.9678 - val_loss: 0.1502 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 19s 741ms/step - loss: 0.1427 - accuracy: 0.9678 - val_loss: 0.1471 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 777ms/step - loss: 0.1382 - accuracy: 0.9678 - val_loss: 0.1417 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 767ms/step - loss: 0.1329 - accuracy: 0.9678 - val_loss: 0.1391 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 757ms/step - loss: 0.1285 - accuracy: 0.9679 - val_loss: 0.1585 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 780ms/step - loss: 0.1644 - accuracy: 0.9679 - val_loss: 0.1595 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 773ms/step - loss: 0.1419 - accuracy: 0.9679 - val_loss: 0.1486 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 765ms/step - loss: 0.1321 - accuracy: 0.9679 - val_loss: 0.1412 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 754ms/step - loss: 0.1244 - accuracy: 0.9679 - val_loss: 0.1373 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 19s 747ms/step - loss: 0.1149 - accuracy: 0.9679 - val_loss: 0.1217 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 758ms/step - loss: 0.1057 - accuracy: 0.9680 - val_loss: 0.1152 - val_accuracy: 0.9673\n",
            "26/26 [==============================] - 20s 760ms/step - loss: 0.1015 - accuracy: 0.9680 - val_loss: 0.1140 - val_accuracy: 0.9674\n",
            "26/26 [==============================] - 19s 740ms/step - loss: 0.0987 - accuracy: 0.9680 - val_loss: 0.1133 - val_accuracy: 0.9674\n",
            "26/26 [==============================] - 19s 739ms/step - loss: 0.0949 - accuracy: 0.9681 - val_loss: 0.1091 - val_accuracy: 0.9675\n",
            "26/26 [==============================] - 19s 739ms/step - loss: 0.0917 - accuracy: 0.9683 - val_loss: 0.1094 - val_accuracy: 0.9676\n"
          ]
        }
      ],
      "source": [
        "results = pd.DataFrame()\n",
        "model_bilstm_lstm = get_bilstm_lstm_model()\n",
        "plot_model(model_bilstm_lstm)\n",
        "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kdWn4VNbi0QQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
          ]
        }
      ],
      "source": [
        "#Visualise model architecture\n",
        "plot_model(model_bilstm_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wWV3MKwnZrPG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2c277fa220>]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Visualise loss curve of 25 epochs\n",
        "plt.plot(results['with_add_lstm'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OSj77s7YlKoM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[22799, 25160, 18327, ..., 35177, 35177, 35177],\n",
              "       [20894,  2154,  6665, ..., 35177, 35177, 35177],\n",
              "       [34191, 30407,   353, ..., 35177, 35177, 35177],\n",
              "       ...,\n",
              "       [32583, 16483,  9536, ..., 35177, 35177, 35177],\n",
              "       [30585, 11033, 19700, ..., 35177, 35177, 35177],\n",
              "       [18236, 16798, 17989, ..., 35177, 35177, 35177]], dtype=int32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f2d2813a5b0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_bilstm_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model_bilstm_lstm.predict(test_tokens)\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=2)\n",
        "\n",
        "y_test = np.argmax(test_tags, axis=2)\n",
        "\n",
        "accuracy = (y_pred == y_test).mean()\n",
        "\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bdG2Hun3N3t"
      },
      "source": [
        "# Domain-specific model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WBZFX1fm0L2"
      },
      "source": [
        "## Import and preprocess domain-specific model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oWYmItQMkzLB"
      },
      "outputs": [],
      "source": [
        "#Prepare dataframe from text file\n",
        "def prepare_data(path):\n",
        "  data = pd.DataFrame(columns=['Sentence', 'Word', 'Tag'])\n",
        "  with open(path) as f:\n",
        "    sentence = 0\n",
        "    for line in f:\n",
        "      if line == '\\n':\n",
        "        sentence += 1\n",
        "      else:\n",
        "        split = line.split(\"\\t\")\n",
        "        word = split[0]\n",
        "        tag = split[1].strip()\n",
        "        new_row = {'Sentence': sentence, 'Word': word, 'Tag': tag}\n",
        "        data = data.append(new_row, ignore_index=True)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xMzWH_KvjUSs"
      },
      "outputs": [],
      "source": [
        "train_path = 'entity-recognition-datasets-master/data/re3d/CONLL-format/data/train/re3d-train.conll'\n",
        "train_df = prepare_data(train_path)\n",
        "test_path = 'entity-recognition-datasets-master/data/re3d/CONLL-format/data/test/re3d-test.conll'\n",
        "test_df = prepare_data(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IJTQcfs_odYp"
      },
      "outputs": [],
      "source": [
        "ds_data = pd.concat([train_df, test_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wJBo_465mkTG"
      },
      "outputs": [],
      "source": [
        "#Get index to word, word to index, index to tag, tag to index mapping\n",
        "idx2word, word2idx = get_dict_map(ds_data, 'Word')\n",
        "idx2tag, tag2idx = get_dict_map(ds_data, 'Tag')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsFDVbJ1urxm",
        "outputId": "efcb6035-7983-405d-8fbb-5b0bfdd07503"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_41365/3682637150.py:8: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  data_group = data.groupby(['Sentence'],as_index=False)['Word', 'Tag', 'Word_index', 'Tag_index'].agg(lambda x: list(x))\n"
          ]
        }
      ],
      "source": [
        "ds_data_group = group_data(ds_data, word2idx, tag2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMVta848mkTJ"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "ArBmO-PAnHNf",
        "outputId": "388f731d-2f3f-43c5-c54e-9eb78e398631"
      },
      "outputs": [],
      "source": [
        "#train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(ds_data_group, ds_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Af7qL6bssOPw"
      },
      "outputs": [],
      "source": [
        "def get_pad_train_test(data_group, data):\n",
        "\n",
        "    #total num of unique words and tags\n",
        "    n_token = len(list(set(data['Word'].to_list())))\n",
        "    n_tag = len(list(set(data['Tag'].to_list())))\n",
        "\n",
        "    #Pad Words (X var)    \n",
        "    words = data_group['Word_index'].tolist()\n",
        "    maxlen = max([len(word) for word in words])\n",
        "    pad_tokens = pad_sequences(words, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
        "\n",
        "    #Pad Tags (y var) and convert it into one hot encoding\n",
        "    tags = data_group['Tag_index'].tolist()\n",
        "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
        "    n_tags = len(tag2idx)\n",
        "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags] #one hot encoding\n",
        "    \n",
        "    #Split train, test and validation set\n",
        "    train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
        "\n",
        "    print(\n",
        "        'train_words length:', len(train_tokens),\n",
        "        '\\ntrain_tags length:', len(train_tags),\n",
        "        '\\ntest_words length:', len(test_tokens),\n",
        "        '\\ntest_tags:', len(test_tags),\n",
        "\n",
        "    )\n",
        "    \n",
        "    return train_tokens, test_tokens, train_tags, test_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwCqa2UPtzEy",
        "outputId": "0fef56be-8b89-411d-9a63-4cb2d9850e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_words length: 688 \n",
            "train_tags length: 688 \n",
            "test_words length: 77 \n",
            "test_tags: 77\n"
          ]
        }
      ],
      "source": [
        "train_tokens, test_tokens, train_tags, test_tags = get_pad_train_test(ds_data_group, ds_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFwEGqBOmkTL"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tyGpPcMWmkTM"
      },
      "outputs": [],
      "source": [
        "seed(1)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzTbdHcomkTN",
        "outputId": "e1dec656-b830-415a-e609-ed530e0a10dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_dim:  4295 \n",
            "output_dim:  64 \n",
            "input_length:  154 \n",
            "n_tags:  21\n"
          ]
        }
      ],
      "source": [
        "input_dim = len(list(set(ds_data['Word'].to_list())))+1\n",
        "output_dim = 64\n",
        "input_length = max([len(s) for s in ds_data_group['Word_index'].tolist()])\n",
        "n_tags = len(tag2idx)\n",
        "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3Ael9GI-mkTO"
      },
      "outputs": [],
      "source": [
        "#Function to initialise and structure NN architecture\n",
        "def get_bilstm_lstm_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add Embedding layer\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "\n",
        "    # Add bidirectional LSTM\n",
        "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
        "\n",
        "    # Add LSTM\n",
        "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
        "\n",
        "    # Add timeDistributed Layer\n",
        "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n",
        "\n",
        "    #Optimiser \n",
        "    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "r22IObwBmkTO"
      },
      "outputs": [],
      "source": [
        "#Function to train model, returns list of losses for each epoch\n",
        "def train_model(X, y, model):\n",
        "    loss = list()\n",
        "    for i in range(25): #run 25 epochs in total\n",
        "        # fit model for one epoch on this sequence\n",
        "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.1)\n",
        "        loss.append(hist.history['loss'][0])\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiLuuxe1mkTP",
        "outputId": "ad1bd85b-52ca-4ce0-89e9-232b5c0e2d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 154, 64)           274880    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 154, 128)         66048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 154, 64)           49408     \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 154, 21)          1365      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 391,701\n",
            "Trainable params: 391,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
            "1/1 [==============================] - 4s 4s/step - loss: 14.3392 - accuracy: 0.0189 - val_loss: 12.2758 - val_accuracy: 0.1645\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 9.5500 - accuracy: 0.1524 - val_loss: 1.3624 - val_accuracy: 0.9217\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 1.4270 - accuracy: 0.7992 - val_loss: 1.0757 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 1.1128 - accuracy: 0.9329 - val_loss: 0.9178 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.9483 - accuracy: 0.9331 - val_loss: 0.8058 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.8287 - accuracy: 0.9331 - val_loss: 0.7181 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.7368 - accuracy: 0.9331 - val_loss: 0.6297 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.6550 - accuracy: 0.9331 - val_loss: 0.5755 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.6005 - accuracy: 0.9331 - val_loss: 0.5489 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.5619 - accuracy: 0.9331 - val_loss: 0.5314 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.5276 - accuracy: 0.9331 - val_loss: 0.5305 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.5110 - accuracy: 0.9331 - val_loss: 0.5303 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.5074 - accuracy: 0.9331 - val_loss: 0.5234 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.4972 - accuracy: 0.9331 - val_loss: 0.5081 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.4793 - accuracy: 0.9331 - val_loss: 0.4826 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.4573 - accuracy: 0.9331 - val_loss: 0.4627 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.4288 - accuracy: 0.9331 - val_loss: 0.4587 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.4288 - accuracy: 0.9331 - val_loss: 0.4589 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.4217 - accuracy: 0.9331 - val_loss: 0.4591 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.4253 - accuracy: 0.9331 - val_loss: 0.4627 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.4239 - accuracy: 0.9331 - val_loss: 0.4646 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.4248 - accuracy: 0.9331 - val_loss: 0.4634 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.4186 - accuracy: 0.9331 - val_loss: 0.4603 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.4191 - accuracy: 0.9331 - val_loss: 0.4614 - val_accuracy: 0.9222\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.4132 - accuracy: 0.9331 - val_loss: 0.4600 - val_accuracy: 0.9222\n"
          ]
        }
      ],
      "source": [
        "results = pd.DataFrame()\n",
        "model_bilstm_lstm = get_bilstm_lstm_model()\n",
        "plot_model(model_bilstm_lstm)\n",
        "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qRZj30oGtnB2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9440\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_bilstm_lstm.predict(test_tokens)\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=2)\n",
        "\n",
        "y_test = np.argmax(test_tags, axis=2)\n",
        "\n",
        "accuracy = (y_pred == y_test).mean()\n",
        "\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tag_conf_matrix(cm, tagid):\n",
        "    tag_name = idx2tag[tagid]\n",
        "    print(\"Tag name: {}\".format(tag_name))\n",
        "    print(cm[tagid])\n",
        "    tn, fp, fn, tp = cm[tagid].ravel()\n",
        "    tag_acc = (tp + tn) / (tn + fp + fn + tp)\n",
        "    print(\"Tag accuracy: {:.3f} \\n\".format(tag_acc))\n",
        "\n",
        "matrix = multilabel_confusion_matrix(y_test.flatten(), y_pred.flatten())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tag_conf_matrix(matrix, 8)\n",
        "tag_conf_matrix(matrix, 14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'B-Money',\n",
              " 1: 'B-Nationality',\n",
              " 2: 'B-Location',\n",
              " 3: 'B-Temporal',\n",
              " 4: 'I-Temporal',\n",
              " 5: 'I-Person',\n",
              " 6: 'B-DocumentReference',\n",
              " 7: 'B-Person',\n",
              " 8: 'I-Quantity',\n",
              " 9: 'B-Quantity',\n",
              " 10: 'B-Organisation',\n",
              " 11: 'I-MilitaryPlatform',\n",
              " 12: 'O',\n",
              " 13: 'I-Nationality',\n",
              " 14: 'B-MilitaryPlatform',\n",
              " 15: 'I-Organisation',\n",
              " 16: 'I-Money',\n",
              " 17: 'I-Weapon',\n",
              " 18: 'B-Weapon',\n",
              " 19: 'I-DocumentReference',\n",
              " 20: 'I-Location'}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred\n",
        "idx2tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3663, 3469, 3685, 2385, 4246,  713, 1454,  119,  688, 2411, 1811,\n",
              "        248,  119,  713, 3193, 1550,  441, 3574, 3193, 2204, 3442, 2209,\n",
              "       3741,  119, 3442,  713,  244, 3768, 3368, 1050,  713,   20, 1708,\n",
              "       3052, 2933, 3768, 1666, 3129, 2939,  688, 1059, 1173, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293,\n",
              "       4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293, 4293],\n",
              "      dtype=int32)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_tokens[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[12, 12, 12, ..., 12, 12, 12],\n",
              "       [12, 12, 12, ..., 12, 12, 12],\n",
              "       [12, 12, 12, ..., 12, 12, 12],\n",
              "       ...,\n",
              "       [12, 12, 12, ..., 12, 12, 12],\n",
              "       [12, 12, 12, ..., 12, 12, 12],\n",
              "       [12, 12, 12, ..., 12, 12, 12]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[12,  7,  5, ..., 12, 12, 12],\n",
              "       [12, 12, 12, ..., 12, 12, 12],\n",
              "       [12, 12, 12, ..., 12, 12, 12],\n",
              "       ...,\n",
              "       [10, 12, 12, ..., 12, 12, 12],\n",
              "       [12, 12, 12, ..., 12, 12, 12],\n",
              "       [10, 15, 12, ..., 12, 12, 12]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "a6a6a43afd82b9c8d81670bbd4cadbd88e22e52abfa29754676dca3e7b854911"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
